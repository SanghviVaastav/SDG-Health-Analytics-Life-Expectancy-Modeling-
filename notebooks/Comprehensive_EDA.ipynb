{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185ed022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprehensive Exploratory Data Analysis for Life Expectancy Dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, shapiro, normaltest\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# â”€â”€ Windows output directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "OUTPUT_DIR = r\"C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def save_fig(filename: str) -> str:\n",
    "    \"\"\"Save figure to the Windows output directory and return the full path.\"\"\"\n",
    "    path = os.path.join(OUTPUT_DIR, filename)\n",
    "    plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ğŸ“Š Visualization saved: {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "class LifeExpectancyEDA:\n",
    "    \"\"\"\n",
    "    Comprehensive EDA class for Life Expectancy dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"Load and initialize the dataset\"\"\"\n",
    "        print(\"=\" * 100)\n",
    "        print(\"LOADING LIFE EXPECTANCY DATASET\")\n",
    "        print(\"=\" * 100)\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        self.df_original = self.df.copy()\n",
    "        print(f\"âœ“ Dataset loaded successfully!\")\n",
    "        print(f\"  Shape: {self.df.shape[0]} rows Ã— {self.df.shape[1]} columns\\n\")\n",
    "\n",
    "    # â”€â”€ 1. BASIC INFO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def basic_info(self):\n",
    "        \"\"\"Display basic dataset information\"\"\"\n",
    "        print(\"=\" * 100)\n",
    "        print(\"1. BASIC DATASET INFORMATION\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        print(\"\\nğŸ“Š Dataset Overview:\")\n",
    "        print(f\"   â€¢ Total Records: {len(self.df):,}\")\n",
    "        print(f\"   â€¢ Total Features: {len(self.df.columns)}\")\n",
    "        print(f\"   â€¢ Memory Usage: {self.df.memory_usage(deep=True).sum() / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "        print(\"\\nğŸ“‹ Column Information:\")\n",
    "        info_df = pd.DataFrame({\n",
    "            'Column': self.df.columns,\n",
    "            'Type': self.df.dtypes.values,\n",
    "            'Non-Null Count': self.df.count().values,\n",
    "            'Null Count': self.df.isnull().sum().values,\n",
    "            'Null %': (self.df.isnull().sum() / len(self.df) * 100).round(2).values,\n",
    "            'Unique Values': [self.df[col].nunique() for col in self.df.columns]\n",
    "        })\n",
    "        print(info_df.to_string(index=False))\n",
    "\n",
    "        print(\"\\nğŸ“ˆ Data Types Distribution:\")\n",
    "        print(self.df.dtypes.value_counts())\n",
    "\n",
    "        return info_df\n",
    "\n",
    "    # â”€â”€ 2. MISSING VALUES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def missing_value_analysis(self):\n",
    "        \"\"\"Comprehensive missing value analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"2. MISSING VALUE ANALYSIS\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        missing = self.df.isnull().sum()\n",
    "        missing_pct = (missing / len(self.df) * 100).round(2)\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Column': missing.index,\n",
    "            'Missing_Count': missing.values,\n",
    "            'Missing_Percentage': missing_pct.values\n",
    "        }).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "        print(\"\\nğŸ” Missing Values Summary:\")\n",
    "        print(missing_df[missing_df['Missing_Count'] > 0].to_string(index=False))\n",
    "\n",
    "        if missing_df['Missing_Count'].sum() == 0:\n",
    "            print(\"\\nâœ“ No missing values detected!\")\n",
    "        else:\n",
    "            print(f\"\\nâš  Total missing values: {missing_df['Missing_Count'].sum():,}\")\n",
    "            print(f\"âš  Columns with missing data: {(missing_df['Missing_Count'] > 0).sum()}\")\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "            missing_cols = missing_df[missing_df['Missing_Count'] > 0].head(10)\n",
    "            if len(missing_cols) > 0:\n",
    "                axes[0].barh(missing_cols['Column'], missing_cols['Missing_Percentage'])\n",
    "                axes[0].set_xlabel('Missing Percentage (%)')\n",
    "                axes[0].set_title('Top 10 Columns with Missing Values')\n",
    "                axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "            plt.sca(axes[1])\n",
    "            sns.heatmap(self.df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "            axes[1].set_title('Missing Value Pattern')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_fig('01_missing_values.png')\n",
    "\n",
    "        return missing_df\n",
    "\n",
    "    # â”€â”€ 3. STATISTICAL SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def statistical_summary(self):\n",
    "        \"\"\"Comprehensive statistical summary\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"3. STATISTICAL SUMMARY\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        print(\"\\nğŸ“Š Descriptive Statistics for Numerical Variables:\")\n",
    "        desc = self.df[numerical_cols].describe()\n",
    "        print(desc.round(2))\n",
    "\n",
    "        print(\"\\nğŸ“ˆ Additional Statistical Measures:\")\n",
    "        additional_stats = pd.DataFrame({\n",
    "            'Column': numerical_cols,\n",
    "            'Median': [self.df[col].median() for col in numerical_cols],\n",
    "            'Mode': [self.df[col].mode()[0] if len(self.df[col].mode()) > 0 else np.nan\n",
    "                     for col in numerical_cols],\n",
    "            'Skewness': [self.df[col].skew() for col in numerical_cols],\n",
    "            'Kurtosis': [self.df[col].kurtosis() for col in numerical_cols],\n",
    "            'CV': [self.df[col].std() / self.df[col].mean() * 100\n",
    "                   if self.df[col].mean() != 0 else np.nan\n",
    "                   for col in numerical_cols]\n",
    "        })\n",
    "        print(additional_stats.round(3).to_string(index=False))\n",
    "\n",
    "        return desc, additional_stats\n",
    "\n",
    "    # â”€â”€ 4. TARGET VARIABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def target_variable_analysis(self, target='LifeExpectancy'):\n",
    "        \"\"\"Deep analysis of target variable (Life Expectancy)\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"4. TARGET VARIABLE ANALYSIS (LIFE EXPECTANCY)\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        if target not in self.df.columns:\n",
    "            print(f\"âš  Warning: '{target}' column not found!\")\n",
    "            return\n",
    "\n",
    "        y = self.df[target].dropna()\n",
    "\n",
    "        print(f\"\\nğŸ“Š Life Expectancy Statistics:\")\n",
    "        print(f\"   â€¢ Mean: {y.mean():.2f} years\")\n",
    "        print(f\"   â€¢ Median: {y.median():.2f} years\")\n",
    "        print(f\"   â€¢ Std Dev: {y.std():.2f} years\")\n",
    "        print(f\"   â€¢ Min: {y.min():.2f} years\")\n",
    "        print(f\"   â€¢ Max: {y.max():.2f} years\")\n",
    "        print(f\"   â€¢ Range: {y.max() - y.min():.2f} years\")\n",
    "        print(f\"   â€¢ IQR: {y.quantile(0.75) - y.quantile(0.25):.2f} years\")\n",
    "        print(f\"   â€¢ Skewness: {y.skew():.3f}\")\n",
    "        print(f\"   â€¢ Kurtosis: {y.kurtosis():.3f}\")\n",
    "\n",
    "        print(f\"\\nğŸ”¬ Normality Tests:\")\n",
    "        shapiro_stat, shapiro_p = shapiro(y.sample(min(5000, len(y))))\n",
    "        print(f\"   â€¢ Shapiro-Wilk: statistic={shapiro_stat:.4f}, p-value={shapiro_p:.4f}\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "        # Histogram with KDE\n",
    "        axes[0, 0].hist(y, bins=50, edgecolor='black', alpha=0.7, density=True)\n",
    "        y.plot(kind='kde', ax=axes[0, 0], color='red', linewidth=2)\n",
    "        axes[0, 0].set_xlabel('Life Expectancy (years)')\n",
    "        axes[0, 0].set_ylabel('Density')\n",
    "        axes[0, 0].set_title(\n",
    "            f'Distribution of Life Expectancy\\nMean: {y.mean():.1f}, Median: {y.median():.1f}')\n",
    "        axes[0, 0].axvline(y.mean(), color='blue', linestyle='--', label='Mean')\n",
    "        axes[0, 0].axvline(y.median(), color='green', linestyle='--', label='Median')\n",
    "        axes[0, 0].legend()\n",
    "\n",
    "        # Box plot\n",
    "        axes[0, 1].boxplot(y, vert=True)\n",
    "        axes[0, 1].set_ylabel('Life Expectancy (years)')\n",
    "        axes[0, 1].set_title('Box Plot - Outlier Detection')\n",
    "        axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # Q-Q plot\n",
    "        stats.probplot(y, dist=\"norm\", plot=axes[0, 2])\n",
    "        axes[0, 2].set_title('Q-Q Plot - Normality Check')\n",
    "\n",
    "        # Violin plot\n",
    "        axes[1, 0].violinplot([y], vert=True, showmeans=True, showmedians=True)\n",
    "        axes[1, 0].set_ylabel('Life Expectancy (years)')\n",
    "        axes[1, 0].set_title('Violin Plot')\n",
    "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # Time series\n",
    "        if 'Year' in self.df.columns:\n",
    "            yearly_life_exp = self.df.groupby('Year')[target].mean()\n",
    "            axes[1, 1].plot(yearly_life_exp.index, yearly_life_exp.values,\n",
    "                            marker='o', linewidth=2)\n",
    "            axes[1, 1].set_xlabel('Year')\n",
    "            axes[1, 1].set_ylabel('Average Life Expectancy')\n",
    "            axes[1, 1].set_title('Life Expectancy Trend Over Years')\n",
    "            axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "        # CDF\n",
    "        sorted_y = np.sort(y)\n",
    "        cumulative = np.arange(1, len(sorted_y) + 1) / len(sorted_y)\n",
    "        axes[1, 2].plot(sorted_y, cumulative, linewidth=2)\n",
    "        axes[1, 2].set_xlabel('Life Expectancy (years)')\n",
    "        axes[1, 2].set_ylabel('Cumulative Probability')\n",
    "        axes[1, 2].set_title('Cumulative Distribution Function')\n",
    "        axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig('02_target_analysis.png')\n",
    "\n",
    "    # â”€â”€ 5. CATEGORICAL ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # FIX 1: method body was de-dented (treated as module-level code).\n",
    "    # FIX 2: Removed the dangling `categorical_analysis_enhanced` stub whose\n",
    "    #         body was also wrongly de-dented and mixed into the module scope.\n",
    "    def categorical_analysis(self):\n",
    "        \"\"\"Analysis of categorical variables\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"5. CATEGORICAL VARIABLE ANALYSIS\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        categorical_cols = self.df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "        if len(categorical_cols) == 0:\n",
    "            print(\"No categorical variables found.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nğŸ“‹ Found {len(categorical_cols)} categorical variables: {categorical_cols}\")\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\n{'â”€' * 80}\")\n",
    "            print(f\"Variable: {col}\")\n",
    "            print(f\"{'â”€' * 80}\")\n",
    "            value_counts = self.df[col].value_counts()\n",
    "            print(f\"   â€¢ Unique values: {self.df[col].nunique()}\")\n",
    "            print(f\"   â€¢ Most common: {value_counts.index[0]} ({value_counts.iloc[0]} occurrences)\")\n",
    "            print(f\"\\n   Distribution:\")\n",
    "            for idx, count in value_counts.items():\n",
    "                percentage = (count / len(self.df) * 100)\n",
    "                print(f\"      {idx}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "        n_cats = len(categorical_cols)\n",
    "        if n_cats > 0:\n",
    "            n_rows = (n_cats + 1) // 2\n",
    "            fig, axes = plt.subplots(n_rows, 2, figsize=(16, 5 * n_rows))\n",
    "\n",
    "            if n_cats == 1:\n",
    "                axes = np.array([[axes]])\n",
    "            axes = axes.flatten()\n",
    "\n",
    "            for idx, col in enumerate(categorical_cols):\n",
    "                value_counts = self.df[col].value_counts()\n",
    "\n",
    "                if col == 'Country' and len(value_counts) > 20:\n",
    "                    value_counts = value_counts.head(20)\n",
    "                    title = f'{col} Distribution (Top 20)'\n",
    "                else:\n",
    "                    title = f'{col} Distribution'\n",
    "\n",
    "                bars = axes[idx].bar(range(len(value_counts)), value_counts.values,\n",
    "                                     color='steelblue', edgecolor='black',\n",
    "                                     linewidth=0.5, alpha=0.8)\n",
    "\n",
    "                max_idx = value_counts.values.argmax()\n",
    "                bars[max_idx].set_color('coral')\n",
    "\n",
    "                axes[idx].set_xticks(range(len(value_counts)))\n",
    "                max_label_length = max(len(str(label)) for label in value_counts.index)\n",
    "                if len(value_counts) > 10 or max_label_length > 8:\n",
    "                    axes[idx].set_xticklabels(value_counts.index, rotation=45,\n",
    "                                              ha='right', fontsize=9)\n",
    "                else:\n",
    "                    axes[idx].set_xticklabels(value_counts.index, rotation=0,\n",
    "                                              fontsize=10)\n",
    "\n",
    "                axes[idx].set_ylabel('Count', fontsize=11, fontweight='bold')\n",
    "                axes[idx].set_title(title, fontsize=12, fontweight='bold', pad=10)\n",
    "                axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "                if len(value_counts) <= 15:\n",
    "                    for i, v in enumerate(value_counts.values):\n",
    "                        axes[idx].text(i, v, str(v), ha='center', va='bottom',\n",
    "                                       fontsize=9, fontweight='bold')\n",
    "\n",
    "                if len(value_counts) <= 5:\n",
    "                    for i, (label, count) in enumerate(value_counts.items()):\n",
    "                        pct = (count / len(self.df)) * 100\n",
    "                        axes[idx].text(i, count / 2, f'{pct:.1f}%',\n",
    "                                       ha='center', va='center',\n",
    "                                       fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "            for idx in range(n_cats, len(axes)):\n",
    "                axes[idx].axis('off')\n",
    "\n",
    "            plt.tight_layout(pad=2.0)\n",
    "            save_fig('03_categorical_analysis.png')\n",
    "\n",
    "    # â”€â”€ 6. CORRELATION ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def correlation_analysis(self, target='LifeExpectancy'):\n",
    "        \"\"\"Comprehensive correlation analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"6. CORRELATION ANALYSIS\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        if len(numerical_cols) < 2:\n",
    "            print(\"Not enough numerical variables for correlation analysis.\")\n",
    "            return\n",
    "\n",
    "        print(\"\\nğŸ“Š Pearson Correlation Matrix (Linear Relationships):\")\n",
    "        corr_matrix = self.df[numerical_cols].corr(method='pearson')\n",
    "        print(corr_matrix.round(3))\n",
    "\n",
    "        if target in numerical_cols:\n",
    "            print(f\"\\nğŸ¯ Correlation with Target Variable ({target}):\")\n",
    "            target_corr = corr_matrix[target].sort_values(ascending=False)\n",
    "            print(target_corr.round(3))\n",
    "\n",
    "            print(f\"\\nğŸ” Top 10 Positively Correlated Features:\")\n",
    "            print(target_corr[target_corr > 0].head(11).to_string())\n",
    "\n",
    "            print(f\"\\nğŸ”» Top 10 Negatively Correlated Features:\")\n",
    "            print(target_corr[target_corr < 0].tail(10).to_string())\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "                    square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, ax=axes[0])\n",
    "        axes[0].set_title('Pearson Correlation Heatmap (All Variables)',\n",
    "                          fontsize=14, fontweight='bold')\n",
    "\n",
    "        if target in numerical_cols:\n",
    "            target_corr_sorted = target_corr.drop(target).sort_values()\n",
    "            colors = ['red' if x < 0 else 'green' for x in target_corr_sorted.values]\n",
    "            axes[1].barh(range(len(target_corr_sorted)), target_corr_sorted.values,\n",
    "                         color=colors, alpha=0.7)\n",
    "            axes[1].set_yticks(range(len(target_corr_sorted)))\n",
    "            axes[1].set_yticklabels(target_corr_sorted.index, fontsize=8)\n",
    "            axes[1].set_xlabel('Correlation Coefficient')\n",
    "            axes[1].set_title(f'Feature Correlation with {target}',\n",
    "                              fontsize=14, fontweight='bold')\n",
    "            axes[1].axvline(0, color='black', linewidth=0.8)\n",
    "            axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig('04_correlation_analysis.png')\n",
    "\n",
    "        print(\"\\nâš  Multicollinearity Detection (High Correlations between Features):\")\n",
    "        high_corr_pairs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i + 1, len(corr_matrix.columns)):\n",
    "                if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "                    high_corr_pairs.append({\n",
    "                        'Feature 1': corr_matrix.columns[i],\n",
    "                        'Feature 2': corr_matrix.columns[j],\n",
    "                        'Correlation': corr_matrix.iloc[i, j]\n",
    "                    })\n",
    "\n",
    "        if high_corr_pairs:\n",
    "            high_corr_df = pd.DataFrame(high_corr_pairs).sort_values(\n",
    "                'Correlation', ascending=False)\n",
    "            print(high_corr_df.to_string(index=False))\n",
    "            print(f\"\\nâš  Warning: {len(high_corr_pairs)} feature pairs with |correlation| > 0.8 detected!\")\n",
    "            print(\"   Consider removing one feature from each pair to avoid multicollinearity.\")\n",
    "        else:\n",
    "            print(\"âœ“ No severe multicollinearity detected (no pairs with |correlation| > 0.8)\")\n",
    "\n",
    "        return corr_matrix, high_corr_pairs\n",
    "\n",
    "    # â”€â”€ 7. OUTLIER DETECTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def outlier_detection(self):\n",
    "        \"\"\"Comprehensive outlier detection\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"7. OUTLIER DETECTION\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        outlier_summary = []\n",
    "\n",
    "        for col in numerical_cols:\n",
    "            data = self.df[col].dropna()\n",
    "            Q1 = data.quantile(0.25)\n",
    "            Q3 = data.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers_iqr = data[(data < lower_bound) | (data > upper_bound)]\n",
    "            outlier_pct = (len(outliers_iqr) / len(data)) * 100\n",
    "            z_scores = np.abs(stats.zscore(data))\n",
    "            outliers_zscore = data[z_scores > 3]\n",
    "\n",
    "            outlier_summary.append({\n",
    "                'Feature': col,\n",
    "                'IQR_Outliers': len(outliers_iqr),\n",
    "                'IQR_Outlier_%': outlier_pct,\n",
    "                'Z-Score_Outliers': len(outliers_zscore),\n",
    "                'Lower_Bound': lower_bound,\n",
    "                'Upper_Bound': upper_bound\n",
    "            })\n",
    "\n",
    "        outlier_df = pd.DataFrame(outlier_summary).sort_values('IQR_Outliers', ascending=False)\n",
    "        print(\"\\nğŸ“Š Outlier Summary (IQR Method):\")\n",
    "        print(outlier_df.round(2).to_string(index=False))\n",
    "\n",
    "        n_cols = len(numerical_cols)\n",
    "        n_rows = (n_cols + 2) // 3\n",
    "        fig, axes = plt.subplots(n_rows, 3, figsize=(18, 5 * n_rows))\n",
    "        axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "\n",
    "        for idx, col in enumerate(numerical_cols):\n",
    "            axes[idx].boxplot(self.df[col].dropna(), vert=True)\n",
    "            axes[idx].set_ylabel(col)\n",
    "            axes[idx].set_title(\n",
    "                f'{col}\\n'\n",
    "                f'({outlier_df[outlier_df[\"Feature\"] == col][\"IQR_Outliers\"].values[0]} outliers)'\n",
    "            )\n",
    "            axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for idx in range(n_cols, len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig('05_outlier_detection.png')\n",
    "\n",
    "        return outlier_df\n",
    "\n",
    "    # â”€â”€ 8. FEATURE DISTRIBUTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def feature_distributions(self):\n",
    "        \"\"\"Analyze distributions of all numerical features\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"8. FEATURE DISTRIBUTION ANALYSIS\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        print(f\"\\nğŸ“Š Analyzing distributions for {len(numerical_cols)} numerical features...\")\n",
    "\n",
    "        n_cols = len(numerical_cols)\n",
    "        n_rows = (n_cols + 2) // 3\n",
    "        fig, axes = plt.subplots(n_rows, 3, figsize=(18, 5 * n_rows))\n",
    "        axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "\n",
    "        for idx, col in enumerate(numerical_cols):\n",
    "            data = self.df[col].dropna()\n",
    "            axes[idx].hist(data, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].set_title(f'{col}\\nSkew: {data.skew():.2f}, Kurt: {data.kurtosis():.2f}')\n",
    "            axes[idx].axvline(data.mean(), color='red', linestyle='--',\n",
    "                              linewidth=2, label='Mean')\n",
    "            axes[idx].axvline(data.median(), color='green', linestyle='--',\n",
    "                              linewidth=2, label='Median')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        for idx in range(n_cols, len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig('06_feature_distributions.png')\n",
    "\n",
    "    # â”€â”€ 9. BIVARIATE ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def bivariate_analysis(self, target='LifeExpectancy'):\n",
    "        \"\"\"Bivariate analysis between features and target\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"9. BIVARIATE ANALYSIS (Features vs Target)\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        if target not in self.df.columns:\n",
    "            print(f\"âš  Warning: Target variable '{target}' not found!\")\n",
    "            return\n",
    "\n",
    "        numerical_cols = [col for col in self.df.select_dtypes(include=[np.number]).columns\n",
    "                          if col != target]\n",
    "\n",
    "        corr_with_target = self.df[numerical_cols + [target]].corr()[target].drop(target)\n",
    "        top_features = corr_with_target.abs().sort_values(ascending=False).head(9).index.tolist()\n",
    "\n",
    "        print(f\"\\nğŸ“Š Analyzing top {len(top_features)} features most correlated with {target}:\")\n",
    "        print(corr_with_target[top_features].to_string())\n",
    "\n",
    "        n_features = len(top_features)\n",
    "        n_rows = (n_features + 2) // 3\n",
    "        fig, axes = plt.subplots(n_rows, 3, figsize=(18, 5 * n_rows))\n",
    "        axes = axes.flatten() if n_features > 1 else [axes]\n",
    "\n",
    "        for idx, feature in enumerate(top_features):\n",
    "            x = self.df[feature].dropna()\n",
    "            y = self.df.loc[x.index, target]\n",
    "\n",
    "            axes[idx].scatter(x, y, alpha=0.5, s=20, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "            z = np.polyfit(x, y, 1)\n",
    "            p = np.poly1d(z)\n",
    "            axes[idx].plot(x, p(x), \"r--\", linewidth=2,\n",
    "                           label=f'y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "\n",
    "            axes[idx].set_xlabel(feature)\n",
    "            axes[idx].set_ylabel(target)\n",
    "            axes[idx].set_title(\n",
    "                f'{feature} vs {target}\\nr = {corr_with_target[feature]:.3f}')\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "\n",
    "        for idx in range(n_features, len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig('07_bivariate_analysis.png')\n",
    "\n",
    "    # â”€â”€ 10. TEMPORAL ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # FIX 3: `temporal_analysis` was defined at MODULE level (missing `self` and\n",
    "    #         wrong indentation). Moved inside the class and fixed the loop body\n",
    "    #         indentation so all axes[idx] calls are inside the for-loop.\n",
    "    def temporal_analysis(self):\n",
    "        \"\"\"Temporal analysis if Year column exists\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"10. TEMPORAL ANALYSIS\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        if 'Year' not in self.df.columns:\n",
    "            print(\"âš  No 'Year' column found. Skipping temporal analysis.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nğŸ“Š Year Range: {self.df['Year'].min()} - {self.df['Year'].max()}\")\n",
    "        print(f\"   Total Years: {self.df['Year'].nunique()}\")\n",
    "\n",
    "        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numerical_cols = [col for col in numerical_cols if col != 'Year']\n",
    "\n",
    "        priority_features = ['LifeExpectancy', 'InfantMortality', 'AdultMortality',\n",
    "                             'GDP', 'Schooling', 'HIV_AIDS']\n",
    "        key_features = [f for f in priority_features if f in numerical_cols][:6]\n",
    "\n",
    "        if len(key_features) < 6:\n",
    "            for col in numerical_cols:\n",
    "                if col not in key_features:\n",
    "                    key_features.append(col)\n",
    "                if len(key_features) >= 6:\n",
    "                    break\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # FIX 4: loop body was de-dented â€” restored correct indentation\n",
    "        for idx, feature in enumerate(key_features[:6]):\n",
    "            yearly_avg = self.df.groupby('Year')[feature].mean()\n",
    "\n",
    "            axes[idx].plot(yearly_avg.index, yearly_avg.values,\n",
    "                           marker='o', linewidth=2.5, markersize=8,\n",
    "                           color='steelblue', label='Average')\n",
    "\n",
    "            z = np.polyfit(yearly_avg.index, yearly_avg.values, 1)\n",
    "            p = np.poly1d(z)\n",
    "            axes[idx].plot(yearly_avg.index, p(yearly_avg.index),\n",
    "                           \"r--\", alpha=0.7, linewidth=2, label='Trend')\n",
    "\n",
    "            axes[idx].set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "            axes[idx].set_ylabel(f'Average {feature}', fontsize=11, fontweight='bold')\n",
    "            axes[idx].set_title(f'{feature} Trend Over Time',\n",
    "                                fontsize=12, fontweight='bold', pad=10)\n",
    "            axes[idx].grid(alpha=0.3, linestyle='--')\n",
    "            axes[idx].legend(loc='best', fontsize=9)\n",
    "\n",
    "            axes[idx].text(yearly_avg.index[0], yearly_avg.values[0],\n",
    "                           f'{yearly_avg.values[0]:.1f}',\n",
    "                           fontsize=9, ha='right', va='bottom')\n",
    "            axes[idx].text(yearly_avg.index[-1], yearly_avg.values[-1],\n",
    "                           f'{yearly_avg.values[-1]:.1f}',\n",
    "                           fontsize=9, ha='left', va='top')\n",
    "\n",
    "            axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.tight_layout(pad=2.0)\n",
    "        save_fig('08_temporal_analysis.png')\n",
    "\n",
    "    # â”€â”€ 11. REGRESSION READINESS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # FIX 5: `regression_readiness_check` was at module level â€” moved inside class.\n",
    "    def regression_readiness_check(self, target='LifeExpectancy'):\n",
    "        \"\"\"Check dataset readiness for regression modeling\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"11. REGRESSION MODELING READINESS CHECK\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        checks = {\n",
    "            'Target Variable Present': target in self.df.columns,\n",
    "            'Sufficient Data Points': len(self.df) >= 100,\n",
    "            'Multiple Features Available': len(\n",
    "                self.df.select_dtypes(include=[np.number]).columns) > 2,\n",
    "            'No Excessive Missing Values': (\n",
    "                self.df.isnull().sum() / len(self.df)).max() < 0.5,\n",
    "            'Target Variable Continuous': (\n",
    "                self.df[target].dtype in [np.float64, np.int64]\n",
    "                if target in self.df.columns else False\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        print(\"\\nâœ“ Regression Readiness Checklist:\")\n",
    "        for check, status in checks.items():\n",
    "            symbol = \"âœ“\" if status else \"âœ—\"\n",
    "            print(f\"   {symbol} {check}: {'PASS' if status else 'FAIL'}\")\n",
    "\n",
    "        all_passed = all(checks.values())\n",
    "\n",
    "        if all_passed:\n",
    "            print(\"\\nğŸ‰ Dataset is READY for regression modeling!\")\n",
    "        else:\n",
    "            print(\"\\nâš  Dataset requires preprocessing before regression modeling.\")\n",
    "\n",
    "        print(\"\\nğŸ“‹ Recommendations for Regression Modeling:\")\n",
    "        print(\"   1. LINEAR REGRESSION:\")\n",
    "        print(\"      â€¢ Use for simple relationships\")\n",
    "        print(\"      â€¢ Select single most correlated feature\")\n",
    "        print(\"      â€¢ Check linearity assumption\")\n",
    "\n",
    "        print(\"\\n   2. MULTIPLE LINEAR REGRESSION:\")\n",
    "        print(\"      â€¢ Use all relevant features\")\n",
    "        print(\"      â€¢ Handle multicollinearity (VIF < 10)\")\n",
    "        print(\"      â€¢ Consider feature scaling\")\n",
    "        print(\"      â€¢ Remove redundant features\")\n",
    "\n",
    "        print(\"\\n   3. POLYNOMIAL REGRESSION:\")\n",
    "        print(\"      â€¢ Use when relationships are non-linear\")\n",
    "        print(\"      â€¢ Start with degree 2 or 3\")\n",
    "        print(\"      â€¢ Watch for overfitting\")\n",
    "        print(\"      â€¢ Use regularization if needed\")\n",
    "\n",
    "        return checks\n",
    "\n",
    "    # â”€â”€ 12. SUMMARY REPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # FIX 6: `generate_summary_report` was at module level â€” moved inside class.\n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"Generate comprehensive summary report\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"12. COMPREHENSIVE EDA SUMMARY REPORT\")\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        print(\"\\nğŸ“Š DATASET OVERVIEW:\")\n",
    "        print(f\"   â€¢ Total Records: {len(self.df):,}\")\n",
    "        print(f\"   â€¢ Total Features: {len(self.df.columns)}\")\n",
    "        print(f\"   â€¢ Numerical Features: {len(self.df.select_dtypes(include=[np.number]).columns)}\")\n",
    "        print(f\"   â€¢ Categorical Features: {len(self.df.select_dtypes(include=['object']).columns)}\")\n",
    "\n",
    "        print(\"\\nğŸ“ˆ DATA QUALITY:\")\n",
    "        missing_pct = (self.df.isnull().sum().sum() /\n",
    "                       (len(self.df) * len(self.df.columns))) * 100\n",
    "        print(f\"   â€¢ Overall Missing Data: {missing_pct:.2f}%\")\n",
    "        print(f\"   â€¢ Columns with Missing Data: {(self.df.isnull().sum() > 0).sum()}\")\n",
    "\n",
    "        print(\"\\nğŸ¯ TARGET VARIABLE (LifeExpectancy):\")\n",
    "        if 'LifeExpectancy' in self.df.columns:\n",
    "            print(f\"   â€¢ Mean: {self.df['LifeExpectancy'].mean():.2f} years\")\n",
    "            print(\n",
    "                f\"   â€¢ Range: {self.df['LifeExpectancy'].min():.2f} - \"\n",
    "                f\"{self.df['LifeExpectancy'].max():.2f} years\"\n",
    "            )\n",
    "            print(f\"   â€¢ Std Dev: {self.df['LifeExpectancy'].std():.2f} years\")\n",
    "\n",
    "        print(\"\\nğŸ” KEY INSIGHTS:\")\n",
    "        print(\"   â€¢ Strong correlations identified between health indicators and life expectancy\")\n",
    "        print(\"   â€¢ Temporal trends show improvement in global health metrics\")\n",
    "        print(\"   â€¢ Dataset suitable for multiple regression approaches\")\n",
    "\n",
    "        print(\"\\nâœ… NEXT STEPS:\")\n",
    "        print(\"   1. Handle missing values (imputation or removal)\")\n",
    "        print(\"   2. Encode categorical variables\")\n",
    "        print(\"   3. Scale numerical features\")\n",
    "        print(\"   4. Split data into train/test sets\")\n",
    "        print(\"   5. Build and compare regression models:\")\n",
    "        print(\"      â€¢ Simple Linear Regression\")\n",
    "        print(\"      â€¢ Multiple Linear Regression\")\n",
    "        print(\"      â€¢ Polynomial Regression (degree 2-3)\")\n",
    "        print(\"   6. Evaluate models using RÂ², RMSE, MAE\")\n",
    "        print(\"   7. Perform residual analysis\")\n",
    "        print(\"   8. Fine-tune best performing model\")\n",
    "\n",
    "    # â”€â”€ MAIN RUNNER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # FIX 7: `run_complete_eda` was at module level â€” moved inside class.\n",
    "    def run_complete_eda(self):\n",
    "        \"\"\"Run all EDA analyses\"\"\"\n",
    "        print(\"\\n\" + \"ğŸ”¬\" * 50)\n",
    "        print(\"STARTING COMPREHENSIVE EDA FOR LIFE EXPECTANCY DATASET\")\n",
    "        print(\"ğŸ”¬\" * 50 + \"\\n\")\n",
    "\n",
    "        self.basic_info()\n",
    "        self.missing_value_analysis()\n",
    "        self.statistical_summary()\n",
    "        self.target_variable_analysis()\n",
    "        self.categorical_analysis()\n",
    "        self.correlation_analysis()\n",
    "        self.outlier_detection()\n",
    "        self.feature_distributions()\n",
    "        self.bivariate_analysis()\n",
    "        self.temporal_analysis()\n",
    "        self.regression_readiness_check()\n",
    "        self.generate_summary_report()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"âœ… COMPREHENSIVE EDA COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"\\nğŸ“Š All visualizations saved in: {OUTPUT_DIR}\")\n",
    "        print(\"   â€¢ 01_missing_values.png\")\n",
    "        print(\"   â€¢ 02_target_analysis.png\")\n",
    "        print(\"   â€¢ 03_categorical_analysis.png\")\n",
    "        print(\"   â€¢ 04_correlation_analysis.png\")\n",
    "        print(\"   â€¢ 05_outlier_detection.png\")\n",
    "        print(\"   â€¢ 06_feature_distributions.png\")\n",
    "        print(\"   â€¢ 07_bivariate_analysis.png\")\n",
    "        print(\"   â€¢ 08_temporal_analysis.png\")\n",
    "        print(\"\\nğŸ‰ Ready to proceed with regression modeling!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa2368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "LOADING LIFE EXPECTANCY DATASET\n",
      "====================================================================================================\n",
      "âœ“ Dataset loaded successfully!\n",
      "  Shape: 2204 rows Ã— 5 columns\n",
      "\n",
      "\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "STARTING COMPREHENSIVE EDA FOR LIFE EXPECTANCY DATASET\n",
      "ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬ğŸ”¬\n",
      "\n",
      "====================================================================================================\n",
      "1. BASIC DATASET INFORMATION\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Dataset Overview:\n",
      "   â€¢ Total Records: 2,204\n",
      "   â€¢ Total Features: 5\n",
      "   â€¢ Memory Usage: 0.33 MB\n",
      "\n",
      "ğŸ“‹ Column Information:\n",
      "         Column    Type  Non-Null Count  Null Count  Null %  Unique Values\n",
      "        Country  object            2204           0     0.0            152\n",
      "           Year   int64            2204           0     0.0             16\n",
      " LifeExpectancy float64            2204           0     0.0            340\n",
      "InfantMortality float64            2204           0     0.0             69\n",
      "         Status  object            2204           0     0.0              1\n",
      "\n",
      "ğŸ“ˆ Data Types Distribution:\n",
      "object     2\n",
      "float64    2\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "====================================================================================================\n",
      "2. MISSING VALUE ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ” Missing Values Summary:\n",
      "Empty DataFrame\n",
      "Columns: [Column, Missing_Count, Missing_Percentage]\n",
      "Index: []\n",
      "\n",
      "âœ“ No missing values detected!\n",
      "\n",
      "====================================================================================================\n",
      "3. STATISTICAL SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Descriptive Statistics for Numerical Variables:\n",
      "          Year  LifeExpectancy  InfantMortality\n",
      "count  2204.00         2204.00          2204.00\n",
      "mean   2007.62           67.85             0.00\n",
      "std       4.61            8.72             1.00\n",
      "min    2000.00           42.30            -1.25\n",
      "25%    2004.00           62.30            -0.75\n",
      "50%    2008.00           69.90            -0.09\n",
      "75%    2012.00           74.20             0.91\n",
      "max    2015.00           89.00             1.80\n",
      "\n",
      "ğŸ“ˆ Additional Statistical Measures:\n",
      "         Column   Median     Mode  Skewness  Kurtosis           CV\n",
      "           Year 2008.000 2013.000    -0.031    -1.212 2.300000e-01\n",
      " LifeExpectancy   69.900   73.000    -0.710    -0.175 1.285100e+01\n",
      "InfantMortality   -0.088   -1.247     0.222    -1.291 1.193292e+18\n",
      "\n",
      "====================================================================================================\n",
      "4. TARGET VARIABLE ANALYSIS (LIFE EXPECTANCY)\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Life Expectancy Statistics:\n",
      "   â€¢ Mean: 67.85 years\n",
      "   â€¢ Median: 69.90 years\n",
      "   â€¢ Std Dev: 8.72 years\n",
      "   â€¢ Min: 42.30 years\n",
      "   â€¢ Max: 89.00 years\n",
      "   â€¢ Range: 46.70 years\n",
      "   â€¢ IQR: 11.90 years\n",
      "   â€¢ Skewness: -0.710\n",
      "   â€¢ Kurtosis: -0.175\n",
      "\n",
      "ğŸ”¬ Normality Tests:\n",
      "   â€¢ Shapiro-Wilk: statistic=0.9430, p-value=0.0000\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\02_target_analysis.png\n",
      "\n",
      "====================================================================================================\n",
      "5. CATEGORICAL VARIABLE ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“‹ Found 2 categorical variables: ['Country', 'Status']\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Variable: Country\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   â€¢ Unique values: 152\n",
      "   â€¢ Most common: Madagascar (16 occurrences)\n",
      "\n",
      "   Distribution:\n",
      "      Madagascar: 16 (0.7%)\n",
      "      Papua New Guinea: 16 (0.7%)\n",
      "      Namibia: 16 (0.7%)\n",
      "      Nepal: 16 (0.7%)\n",
      "      Nicaragua: 16 (0.7%)\n",
      "      Niger: 16 (0.7%)\n",
      "      Oman: 16 (0.7%)\n",
      "      Panama: 16 (0.7%)\n",
      "      Paraguay: 16 (0.7%)\n",
      "      Saint Vincent and the Grenadines: 16 (0.7%)\n",
      "      Peru: 16 (0.7%)\n",
      "      Qatar: 16 (0.7%)\n",
      "      Republic of Korea: 16 (0.7%)\n",
      "      Republic of Moldova: 16 (0.7%)\n",
      "      Russian Federation: 16 (0.7%)\n",
      "      Rwanda: 16 (0.7%)\n",
      "      Morocco: 16 (0.7%)\n",
      "      Montenegro: 16 (0.7%)\n",
      "      Mongolia: 16 (0.7%)\n",
      "      Micronesia (Federated States of): 16 (0.7%)\n",
      "      Mexico: 16 (0.7%)\n",
      "      Mauritius: 16 (0.7%)\n",
      "      Mauritania: 16 (0.7%)\n",
      "      Mali: 16 (0.7%)\n",
      "      Maldives: 16 (0.7%)\n",
      "      Malaysia: 16 (0.7%)\n",
      "      Malawi: 16 (0.7%)\n",
      "      Albania: 16 (0.7%)\n",
      "      Libya: 16 (0.7%)\n",
      "      Liberia: 16 (0.7%)\n",
      "      Lesotho: 16 (0.7%)\n",
      "      Lebanon: 16 (0.7%)\n",
      "      Lao People's Democratic Republic: 16 (0.7%)\n",
      "      Saint Lucia: 16 (0.7%)\n",
      "      Samoa: 16 (0.7%)\n",
      "      Kuwait: 16 (0.7%)\n",
      "      United Arab Emirates: 16 (0.7%)\n",
      "      Tonga: 16 (0.7%)\n",
      "      Trinidad and Tobago: 16 (0.7%)\n",
      "      Tunisia: 16 (0.7%)\n",
      "      Turkey: 16 (0.7%)\n",
      "      Turkmenistan: 16 (0.7%)\n",
      "      Ukraine: 16 (0.7%)\n",
      "      Uruguay: 16 (0.7%)\n",
      "      Sao Tome and Principe: 16 (0.7%)\n",
      "      Uzbekistan: 16 (0.7%)\n",
      "      Vanuatu: 16 (0.7%)\n",
      "      Venezuela (Bolivarian Republic of): 16 (0.7%)\n",
      "      Viet Nam: 16 (0.7%)\n",
      "      Yemen: 16 (0.7%)\n",
      "      Zambia: 16 (0.7%)\n",
      "      Togo: 16 (0.7%)\n",
      "      Timor-Leste: 16 (0.7%)\n",
      "      The former Yugoslav republic of Macedonia: 16 (0.7%)\n",
      "      Thailand: 16 (0.7%)\n",
      "      Tajikistan: 16 (0.7%)\n",
      "      Syrian Arab Republic: 16 (0.7%)\n",
      "      Swaziland: 16 (0.7%)\n",
      "      Suriname: 16 (0.7%)\n",
      "      Sri Lanka: 16 (0.7%)\n",
      "      South Sudan: 16 (0.7%)\n",
      "      South Africa: 16 (0.7%)\n",
      "      Somalia: 16 (0.7%)\n",
      "      Solomon Islands: 16 (0.7%)\n",
      "      Seychelles: 16 (0.7%)\n",
      "      Serbia: 16 (0.7%)\n",
      "      Senegal: 16 (0.7%)\n",
      "      Saudi Arabia: 16 (0.7%)\n",
      "      Kyrgyzstan: 16 (0.7%)\n",
      "      Zimbabwe: 16 (0.7%)\n",
      "      Kiribati: 16 (0.7%)\n",
      "      Chad: 16 (0.7%)\n",
      "      CÃ´te d'Ivoire: 16 (0.7%)\n",
      "      Cabo Verde: 16 (0.7%)\n",
      "      Cambodia: 16 (0.7%)\n",
      "      Cameroon: 16 (0.7%)\n",
      "      Canada: 16 (0.7%)\n",
      "      Central African Republic: 16 (0.7%)\n",
      "      Chile: 16 (0.7%)\n",
      "      Burkina Faso: 16 (0.7%)\n",
      "      Colombia: 16 (0.7%)\n",
      "      Comoros: 16 (0.7%)\n",
      "      Congo: 16 (0.7%)\n",
      "      Costa Rica: 16 (0.7%)\n",
      "      Cuba: 16 (0.7%)\n",
      "      Djibouti: 16 (0.7%)\n",
      "      Burundi: 16 (0.7%)\n",
      "      Brunei Darussalam: 16 (0.7%)\n",
      "      Ecuador: 16 (0.7%)\n",
      "      Bahrain: 16 (0.7%)\n",
      "      Algeria: 16 (0.7%)\n",
      "      Antigua and Barbuda: 16 (0.7%)\n",
      "      Argentina: 16 (0.7%)\n",
      "      Armenia: 16 (0.7%)\n",
      "      Azerbaijan: 16 (0.7%)\n",
      "      Bahamas: 16 (0.7%)\n",
      "      Barbados: 16 (0.7%)\n",
      "      Botswana: 16 (0.7%)\n",
      "      Belarus: 16 (0.7%)\n",
      "      Belize: 16 (0.7%)\n",
      "      Benin: 16 (0.7%)\n",
      "      Bhutan: 16 (0.7%)\n",
      "      Bolivia (Plurinational State of): 16 (0.7%)\n",
      "      Bosnia and Herzegovina: 16 (0.7%)\n",
      "      Dominican Republic: 16 (0.7%)\n",
      "      Democratic People's Republic of Korea: 16 (0.7%)\n",
      "      Egypt: 16 (0.7%)\n",
      "      Guyana: 16 (0.7%)\n",
      "      Ghana: 16 (0.7%)\n",
      "      Greece: 16 (0.7%)\n",
      "      Grenada: 16 (0.7%)\n",
      "      Guatemala: 16 (0.7%)\n",
      "      Guinea: 16 (0.7%)\n",
      "      Guinea-Bissau: 16 (0.7%)\n",
      "      Honduras: 16 (0.7%)\n",
      "      Gabon: 16 (0.7%)\n",
      "      Iran (Islamic Republic of): 16 (0.7%)\n",
      "      Iraq: 16 (0.7%)\n",
      "      Israel: 16 (0.7%)\n",
      "      Jamaica: 16 (0.7%)\n",
      "      Jordan: 16 (0.7%)\n",
      "      Kazakhstan: 16 (0.7%)\n",
      "      Gambia: 16 (0.7%)\n",
      "      Georgia: 16 (0.7%)\n",
      "      Equatorial Guinea: 16 (0.7%)\n",
      "      Finland: 16 (0.7%)\n",
      "      Eritrea: 16 (0.7%)\n",
      "      Fiji: 16 (0.7%)\n",
      "      El Salvador: 16 (0.7%)\n",
      "      Estonia: 16 (0.7%)\n",
      "      France: 16 (0.7%)\n",
      "      Philippines: 15 (0.7%)\n",
      "      Haiti: 15 (0.7%)\n",
      "      Sierra Leone: 13 (0.6%)\n",
      "      Sudan: 12 (0.5%)\n",
      "      Myanmar: 12 (0.5%)\n",
      "      Kenya: 10 (0.5%)\n",
      "      Brazil: 9 (0.4%)\n",
      "      Mozambique: 5 (0.2%)\n",
      "      Afghanistan: 3 (0.1%)\n",
      "      Uganda: 2 (0.1%)\n",
      "      Angola: 2 (0.1%)\n",
      "      Saint Kitts and Nevis: 1 (0.0%)\n",
      "      Dominica: 1 (0.0%)\n",
      "      Nauru: 1 (0.0%)\n",
      "      San Marino: 1 (0.0%)\n",
      "      Tuvalu: 1 (0.0%)\n",
      "      Cook Islands: 1 (0.0%)\n",
      "      Palau: 1 (0.0%)\n",
      "      Niue: 1 (0.0%)\n",
      "      Monaco: 1 (0.0%)\n",
      "      Marshall Islands: 1 (0.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Variable: Status\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   â€¢ Unique values: 1\n",
      "   â€¢ Most common: Developing (2204 occurrences)\n",
      "\n",
      "   Distribution:\n",
      "      Developing: 2204 (100.0%)\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\03_categorical_analysis.png\n",
      "\n",
      "====================================================================================================\n",
      "6. CORRELATION ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Pearson Correlation Matrix (Linear Relationships):\n",
      "                  Year  LifeExpectancy  InfantMortality\n",
      "Year             1.000           0.166           -0.028\n",
      "LifeExpectancy   0.166           1.000           -0.538\n",
      "InfantMortality -0.028          -0.538            1.000\n",
      "\n",
      "ğŸ¯ Correlation with Target Variable (LifeExpectancy):\n",
      "LifeExpectancy     1.000\n",
      "Year               0.166\n",
      "InfantMortality   -0.538\n",
      "Name: LifeExpectancy, dtype: float64\n",
      "\n",
      "ğŸ” Top 10 Positively Correlated Features:\n",
      "LifeExpectancy    1.000000\n",
      "Year              0.166058\n",
      "\n",
      "ğŸ”» Top 10 Negatively Correlated Features:\n",
      "InfantMortality   -0.53774\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\04_correlation_analysis.png\n",
      "\n",
      "âš  Multicollinearity Detection (High Correlations between Features):\n",
      "âœ“ No severe multicollinearity detected (no pairs with |correlation| > 0.8)\n",
      "\n",
      "====================================================================================================\n",
      "7. OUTLIER DETECTION\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Outlier Summary (IQR Method):\n",
      "        Feature  IQR_Outliers  IQR_Outlier_%  Z-Score_Outliers  Lower_Bound  Upper_Bound\n",
      " LifeExpectancy             8           0.36                 0        44.45        92.05\n",
      "           Year             0           0.00                 0      1992.00      2024.00\n",
      "InfantMortality             0           0.00                 0        -3.24         3.40\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\05_outlier_detection.png\n",
      "\n",
      "====================================================================================================\n",
      "8. FEATURE DISTRIBUTION ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Analyzing distributions for 3 numerical features...\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\06_feature_distributions.png\n",
      "\n",
      "====================================================================================================\n",
      "9. BIVARIATE ANALYSIS (Features vs Target)\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Analyzing top 2 features most correlated with LifeExpectancy:\n",
      "InfantMortality   -0.537740\n",
      "Year               0.166058\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\07_bivariate_analysis.png\n",
      "\n",
      "====================================================================================================\n",
      "10. TEMPORAL ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š Year Range: 2000 - 2015\n",
      "   Total Years: 16\n",
      "   ğŸ“Š Visualization saved: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\\08_temporal_analysis.png\n",
      "\n",
      "====================================================================================================\n",
      "11. REGRESSION MODELING READINESS CHECK\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Regression Readiness Checklist:\n",
      "   âœ“ Target Variable Present: PASS\n",
      "   âœ“ Sufficient Data Points: PASS\n",
      "   âœ“ Multiple Features Available: PASS\n",
      "   âœ“ No Excessive Missing Values: PASS\n",
      "   âœ“ Target Variable Continuous: PASS\n",
      "\n",
      "ğŸ‰ Dataset is READY for regression modeling!\n",
      "\n",
      "ğŸ“‹ Recommendations for Regression Modeling:\n",
      "   1. LINEAR REGRESSION:\n",
      "      â€¢ Use for simple relationships\n",
      "      â€¢ Select single most correlated feature\n",
      "      â€¢ Check linearity assumption\n",
      "\n",
      "   2. MULTIPLE LINEAR REGRESSION:\n",
      "      â€¢ Use all relevant features\n",
      "      â€¢ Handle multicollinearity (VIF < 10)\n",
      "      â€¢ Consider feature scaling\n",
      "      â€¢ Remove redundant features\n",
      "\n",
      "   3. POLYNOMIAL REGRESSION:\n",
      "      â€¢ Use when relationships are non-linear\n",
      "      â€¢ Start with degree 2 or 3\n",
      "      â€¢ Watch for overfitting\n",
      "      â€¢ Use regularization if needed\n",
      "\n",
      "====================================================================================================\n",
      "12. COMPREHENSIVE EDA SUMMARY REPORT\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š DATASET OVERVIEW:\n",
      "   â€¢ Total Records: 2,204\n",
      "   â€¢ Total Features: 5\n",
      "   â€¢ Numerical Features: 3\n",
      "   â€¢ Categorical Features: 2\n",
      "\n",
      "ğŸ“ˆ DATA QUALITY:\n",
      "   â€¢ Overall Missing Data: 0.00%\n",
      "   â€¢ Columns with Missing Data: 0\n",
      "\n",
      "ğŸ¯ TARGET VARIABLE (LifeExpectancy):\n",
      "   â€¢ Mean: 67.85 years\n",
      "   â€¢ Range: 42.30 - 89.00 years\n",
      "   â€¢ Std Dev: 8.72 years\n",
      "\n",
      "ğŸ” KEY INSIGHTS:\n",
      "   â€¢ Strong correlations identified between health indicators and life expectancy\n",
      "   â€¢ Temporal trends show improvement in global health metrics\n",
      "   â€¢ Dataset suitable for multiple regression approaches\n",
      "\n",
      "âœ… NEXT STEPS:\n",
      "   1. Handle missing values (imputation or removal)\n",
      "   2. Encode categorical variables\n",
      "   3. Scale numerical features\n",
      "   4. Split data into train/test sets\n",
      "   5. Build and compare regression models:\n",
      "      â€¢ Simple Linear Regression\n",
      "      â€¢ Multiple Linear Regression\n",
      "      â€¢ Polynomial Regression (degree 2-3)\n",
      "   6. Evaluate models using RÂ², RMSE, MAE\n",
      "   7. Perform residual analysis\n",
      "   8. Fine-tune best performing model\n",
      "\n",
      "====================================================================================================\n",
      "âœ… COMPREHENSIVE EDA COMPLETED SUCCESSFULLY!\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“Š All visualizations saved in: C:\\Users\\sejal\\OneDrive\\Desktop\\Comprehensive EDA\n",
      "   â€¢ 01_missing_values.png\n",
      "   â€¢ 02_target_analysis.png\n",
      "   â€¢ 03_categorical_analysis.png\n",
      "   â€¢ 04_correlation_analysis.png\n",
      "   â€¢ 05_outlier_detection.png\n",
      "   â€¢ 06_feature_distributions.png\n",
      "   â€¢ 07_bivariate_analysis.png\n",
      "   â€¢ 08_temporal_analysis.png\n",
      "\n",
      "ğŸ‰ Ready to proceed with regression modeling!\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize EDA\n",
    "    eda = LifeExpectancyEDA('C:\\\\Users\\\\sejal\\\\OneDrive\\\\Desktop\\\\Comprehensive EDA\\\\life_expectancy_cleaned.csv')\n",
    "    \n",
    "    # Run complete EDA\n",
    "    eda.run_complete_eda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
